dataset = read.csv('winequality.csv')
# Problem: Predict the quality of red wine based on sugar, acidity, and other factors.
# Importing the dataset
dataset = read.csv('winequality.csv')
setwd("~/Desktop/Data Mining and Visualization/WORKSPACE/wine_quality_predictor")
# Problem: Predict the quality of red wine based on sugar, acidity, and other factors.
# Importing the dataset
dataset = read.csv('winequality.csv')
dataset$quality = as.factor(ifelse(dataset$quality >= 6, 1, 0))
# Splitting the dataset into the Training set and Test set
library(caTools)
split = sample.split(dataset$quality, SplitRatio = 3/4)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_scaled_cols = scale(training_set[, 1:11])
training_set[, 1:11] = training_scaled_cols
test_set[, 1:11] = scale(test_set[, 1:11],
center = attr(training_scaled_cols, 'scaled:center'),
scale = attr(training_scaled_cols, 'scaled:scale'))
# MODELS
# KNN
library(kknn)
install.packages("kknn")
# Problem: Predict the quality of red wine based on sugar, acidity, and other factors.
# Importing the dataset
dataset = read.csv('winequality.csv')
dataset$quality = as.factor(ifelse(dataset$quality >= 6, 1, 0))
# Splitting the dataset into the Training set and Test set
library(caTools)
split = sample.split(dataset$quality, SplitRatio = 3/4)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_scaled_cols = scale(training_set[, 1:11])
training_set[, 1:11] = training_scaled_cols
test_set[, 1:11] = scale(test_set[, 1:11],
center = attr(training_scaled_cols, 'scaled:center'),
scale = attr(training_scaled_cols, 'scaled:scale'))
# MODELS
# KNN
library(kknn)
# Fitting k-NN to the Training set and Predicting the Test set results
classifier = kknn(formula = quality ~ ., train = training_set, test = test_set,
k = 7, distance = 2)
y_pred = classifier$fitted.values
# Showing the Confusion Matrix and Accuracy
library(caret)
cm = confusionMatrix(y_pred, test_set$quality)
print(cm$table)
print(cm$overall['Accuracy'])
classifier = glm(formula = quality ~ .,
family = binomial,
data = training_set)
# Predicting the Test set results
prob_pred = predict(classifier, type = 'response', newdata = test_set)
y_pred = as.factor(ifelse(prob_pred > 0.5, 1, 0))
library(caret)
cm = confusionMatrix(y_pred, test_set$Purchased)
library(caret)
cm = confusionMatrix(y_pred, test_set$quality)
print(cm$table)
print(cm$overall['Accuracy'])
# Problem: Predict the quality of red wine based on sugar, acidity, and other factors.
# Importing the dataset
dataset = read.csv('winequality.csv')
dataset$quality = as.factor(ifelse(dataset$quality >= 6, 1, 0))
# Splitting the dataset into the Training set and Test set
library(caTools)
split = sample.split(dataset$quality, SplitRatio = 3/4)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_scaled_cols = scale(training_set[, 1:11])
training_set[, 1:11] = training_scaled_cols
test_set[, 1:11] = scale(test_set[, 1:11],
center = attr(training_scaled_cols, 'scaled:center'),
scale = attr(training_scaled_cols, 'scaled:scale'))
# MODELS
# KNN
library(kknn)
# Fitting k-NN to the Training set and Predicting the Test set results
classifier = kknn(formula = quality ~ ., train = training_set, test = test_set,
k = 7, distance = 2)
y_pred = classifier$fitted.values
# Showing the Confusion Matrix and Accuracy
library(caret)
cm = confusionMatrix(y_pred, test_set$quality)
print(cm$table)
print(cm$overall['Accuracy'])
# LOGISTIC REGRESSION
# Fitting Logistic Regression to the Training set
classifier = glm(formula = quality ~ .,
family = binomial,
data = training_set)
# Predicting the Test set results
prob_pred = predict(classifier, type = 'response', newdata = test_set)
y_pred = as.factor(ifelse(prob_pred > 0.5, 1, 0))
library(caret)
cm = confusionMatrix(y_pred, test_set$quality)
print(cm$table)
print(cm$overall['Accuracy'])
# Problem: Predict the quality of red wine based on sugar, acidity, and other factors.
# Importing the dataset
dataset = read.csv('winequality.csv')
dataset$quality = as.factor(ifelse(dataset$quality >= 6, 1, 0))
# Splitting the dataset into the Training set and Test set
library(caTools)
split = sample.split(dataset$quality, SplitRatio = 3/4)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_scaled_cols = scale(training_set[, 1:11])
training_set[, 1:11] = training_scaled_cols
test_set[, 1:11] = scale(test_set[, 1:11],
center = attr(training_scaled_cols, 'scaled:center'),
scale = attr(training_scaled_cols, 'scaled:scale'))
# MODELS
# KNN
library(kknn)
# Fitting k-NN to the Training set and Predicting the Test set results
classifier = kknn(formula = quality ~ ., train = training_set, test = test_set,
k = 7, distance = 2)
y_pred = classifier$fitted.values
# Showing the Confusion Matrix and Accuracy
library(caret)
cm = confusionMatrix(y_pred, test_set$quality)
print(cm$table)
print(cm$overall['Accuracy'])
# LOGISTIC REGRESSION
# Fitting Logistic Regression to the Training set
classifier = glm(formula = quality ~ .,
family = binomial,
data = training_set)
# Predicting the Test set results
prob_pred = predict(classifier, type = 'response', newdata = test_set)
y_pred = as.factor(ifelse(prob_pred > 0.5, 1, 0))
library(caret)
cm = confusionMatrix(y_pred, test_set$quality)
print(cm$table)
print(cm$overall['Accuracy'])
# Problem: Predict the quality of red wine based on sugar, acidity, and other factors.
# Importing the dataset
dataset = read.csv('winequality.csv')
dataset$quality = as.factor(ifelse(dataset$quality >= 6, 1, 0))
# Splitting the dataset into the Training set and Test set
library(caTools)
split = sample.split(dataset$quality, SplitRatio = 3/4)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_scaled_cols = scale(training_set[, 1:11])
training_set[, 1:11] = training_scaled_cols
test_set[, 1:11] = scale(test_set[, 1:11],
center = attr(training_scaled_cols, 'scaled:center'),
scale = attr(training_scaled_cols, 'scaled:scale'))
# MODELS
# KNN
library(kknn)
# Fitting k-NN to the Training set and Predicting the Test set results
classifier = kknn(formula = quality ~ ., train = training_set, test = test_set,
k = 7, distance = 2)
y_pred = classifier$fitted.values
# Showing the Confusion Matrix and Accuracy
library(caret)
cm = confusionMatrix(y_pred, test_set$quality)
print(cm$table)
print(cm$overall['Accuracy'])
# LOGISTIC REGRESSION
# Fitting Logistic Regression to the Training set
classifier = glm(formula = quality ~ .,
family = binomial,
data = training_set)
# Predicting the Test set results
prob_pred = predict(classifier, type = 'response', newdata = test_set)
y_pred = as.factor(ifelse(prob_pred > 0.5, 1, 0))
library(caret)
cm = confusionMatrix(y_pred, test_set$quality)
print(cm$table)
print(cm$overall['Accuracy'])
# Problem: Predict the quality of red wine based on sugar, acidity, and other factors.
# Importing the dataset
dataset = read.csv('winequality.csv')
dataset$quality = as.factor(ifelse(dataset$quality >= 6, 1, 0))
# Splitting the dataset into the Training set and Test set
library(caTools)
split = sample.split(dataset$quality, SplitRatio = 3/4)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_scaled_cols = scale(training_set[, 1:11])
training_set[, 1:11] = training_scaled_cols
test_set[, 1:11] = scale(test_set[, 1:11],
center = attr(training_scaled_cols, 'scaled:center'),
scale = attr(training_scaled_cols, 'scaled:scale'))
# MODELS
# KNN
library(kknn)
# Fitting k-NN to the Training set and Predicting the Test set results
classifier = kknn(formula = quality ~ ., train = training_set, test = test_set,
k = 7, distance = 2)
y_pred = classifier$fitted.values
# Showing the Confusion Matrix and Accuracy
library(caret)
cm = confusionMatrix(y_pred, test_set$quality)
print(cm$table)
print(cm$overall['Accuracy'])
# LOGISTIC REGRESSION
# Fitting Logistic Regression to the Training set
classifier = glm(formula = quality ~ .,
family = binomial,
data = training_set)
# Predicting the Test set results
prob_pred = predict(classifier, type = 'response', newdata = test_set)
y_pred = as.factor(ifelse(prob_pred > 0.5, 1, 0))
library(caret)
cm = confusionMatrix(y_pred, test_set$quality)
print(cm$table)
print(cm$overall['Accuracy'])
# Problem: Predict the quality of red wine based on sugar, acidity, and other factors.
# Importing the dataset
dataset = read.csv('winequality.csv')
dataset$quality = as.factor(ifelse(dataset$quality >= 6, 1, 0))
# Splitting the dataset into the Training set and Test set
library(caTools)
split = sample.split(dataset$quality, SplitRatio = 3/4)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_scaled_cols = scale(training_set[, 1:11])
training_set[, 1:11] = training_scaled_cols
test_set[, 1:11] = scale(test_set[, 1:11],
center = attr(training_scaled_cols, 'scaled:center'),
scale = attr(training_scaled_cols, 'scaled:scale'))
# MODELS
# KNN
library(kknn)
# Fitting k-NN to the Training set and Predicting the Test set results
classifier = kknn(formula = quality ~ ., train = training_set, test = test_set,
k = 7, distance = 2)
y_pred = classifier$fitted.values
# Showing the Confusion Matrix and Accuracy
library(caret)
cm = confusionMatrix(y_pred, test_set$quality)
print(cm$table)
print(cm$overall['Accuracy'])
# LOGISTIC REGRESSION
# Fitting Logistic Regression to the Training set
classifier = glm(formula = quality ~ .,
family = binomial,
data = training_set)
# Predicting the Test set results
prob_pred = predict(classifier, type = 'response', newdata = test_set)
y_pred = as.factor(ifelse(prob_pred > 0.5, 1, 0))
library(caret)
cm = confusionMatrix(y_pred, test_set$quality)
print(cm$table)
print(cm$overall['Accuracy'])
# Problem: Predict the quality of red wine based on sugar, acidity, and other factors.
# Importing the dataset
dataset = read.csv('winequality.csv')
dataset$quality = as.factor(ifelse(dataset$quality >= 6, 1, 0))
# Splitting the dataset into the Training set and Test set
library(caTools)
split = sample.split(dataset$quality, SplitRatio = 3/4)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_scaled_cols = scale(training_set[, 1:11])
training_set[, 1:11] = training_scaled_cols
test_set[, 1:11] = scale(test_set[, 1:11],
center = attr(training_scaled_cols, 'scaled:center'),
scale = attr(training_scaled_cols, 'scaled:scale'))
# MODELS
# KNN
library(kknn)
# Fitting k-NN to the Training set and Predicting the Test set results
classifier = kknn(formula = quality ~ ., train = training_set, test = test_set,
k = 7, distance = 2)
y_pred = classifier$fitted.values
# Showing the Confusion Matrix and Accuracy
library(caret)
cm = confusionMatrix(y_pred, test_set$quality)
print(cm$table)
print(cm$overall['Accuracy'])
# LOGISTIC REGRESSION
# Fitting Logistic Regression to the Training set
classifier = glm(formula = quality ~ .,
family = binomial,
data = training_set)
# Predicting the Test set results
prob_pred = predict(classifier, type = 'response', newdata = test_set)
y_pred = as.factor(ifelse(prob_pred > 0.5, 1, 0))
library(caret)
cm = confusionMatrix(y_pred, test_set$quality)
print(cm$table)
print(cm$overall['Accuracy'])
# Importing the dataset
dataset = read.csv('winequality.csv')
# Splitting the dataset into the Training set and Test set
library(caTools)
split = sample.split(dataset$quality, SplitRatio = 3/4)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Random Forest
library(randomForest)
regressor = randomForest(formula = quality ~ .,
data = training_set,
ntree = 500)
# Predict y
y_pred = predict(regressor, newdata = test_set)
# Calculate R-squared
ssr = sum((test_set$quality - y_pred) ^ 2)
sst = sum((test_set$quality - mean(test_set$quality)) ^ 2)
r2 = 1 - (ssr/sst)
print(r2)
r2_adjusted = 1 - (1 - r2) * (length(test_set$quality) - 1) / (length(test_set$quality) - 11 - 1)
print(r2_adjusted)
######################################################################################
#POLYNOMIAL
#####################################################################################
dataset = read.csv('winequality.csv')
#free sulfur dioxide
#ph
# the above variables increase as the degree increase
regressor = lm(formula = quality ~ .,
data = dataset)
summary(regressor)
dataset$quality = dataset$quality^2
regressor = lm(formula = quality ~ .,
data = dataset)
summary(regressor)
dataset$quality = dataset$quality^3
regressor = lm(formula = quality ~ .,
data = dataset)
summary(regressor)
# Fitting Logistic Regression to the Training set
classifier = glm(formula = quality ~ .,
family = binomial,
data = training_set)
classifier = glm(formula = quality ~ .,
family = binomial,
data = training_set)
# Problem: Predict the quality of red wine based on sugar, acidity, and other factors.
# Importing the dataset
dataset = read.csv('winequality.csv')
dataset$quality = as.factor(ifelse(dataset$quality >= 6, 1, 0))
# Splitting the dataset into the Training set and Test set
library(caTools)
split = sample.split(dataset$quality, SplitRatio = 3/4)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_scaled_cols = scale(training_set[, 1:11])
training_set[, 1:11] = training_scaled_cols
test_set[, 1:11] = scale(test_set[, 1:11],
center = attr(training_scaled_cols, 'scaled:center'),
scale = attr(training_scaled_cols, 'scaled:scale'))
# Fitting Logistic Regression to the Training set
classifier = glm(formula = quality ~ .,
family = binomial,
data = training_set)
# Predicting the Test set results
prob_pred = predict(classifier, type = 'response', newdata = test_set)
y_pred = as.factor(ifelse(prob_pred > 0.5, 1, 0))
# Showing the Confusion Matrix and Accuracy
library(caret)
cm = confusionMatrix(y_pred, test_set$quality)
print(cm$table)
print(cm$overall['Accuracy'])
# Problem: Predict the quality of red wine based on sugar, acidity, and other factors.
# Importing the dataset
dataset = read.csv('winequality.csv')
dataset$quality = as.factor(ifelse(dataset$quality >= 6, 1, 0))
# Splitting the dataset into the Training set and Test set
library(caTools)
split = sample.split(dataset$quality, SplitRatio = 3/4)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_scaled_cols = scale(training_set[, 1:11])
training_set[, 1:11] = training_scaled_cols
test_set[, 1:11] = scale(test_set[, 1:11],
center = attr(training_scaled_cols, 'scaled:center'),
scale = attr(training_scaled_cols, 'scaled:scale'))
# MODELS
# KNN
library(kknn)
# Fitting k-NN to the Training set and Predicting the Test set results
classifier = kknn(formula = quality ~ ., train = training_set, test = test_set,
k = 7, distance = 2)
y_pred = classifier$fitted.values
# Showing the Confusion Matrix and Accuracy
library(caret)
cm = confusionMatrix(y_pred, test_set$quality)
print(cm$table)
print(cm$overall['Accuracy'])
# LOGISTIC REGRESSION
# Fitting Logistic Regression to the Training set
classifier = glm(formula = quality ~ .,
family = binomial,
data = training_set)
# Predicting the Test set results
prob_pred = predict(classifier, type = 'response', newdata = test_set)
y_pred = as.factor(ifelse(prob_pred > 0.5, 1, 0))
# Showing the Confusion Matrix and Accuracy
library(caret)
cm = confusionMatrix(y_pred, test_set$quality)
print(cm$table)
print(cm$overall['Accuracy'])
View(dataset)
View(dataset)
# Problem: Predict the quality of red wine based on sugar, acidity, and other factors.
# Importing the dataset
dataset = read.csv('winequality.csv')
dataset$quality = as.factor(ifelse(dataset$quality >= 6, 1, 0))
# Splitting the dataset into the Training set and Test set
library(caTools)
split = sample.split(dataset$quality, SplitRatio = 3/4)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_scaled_cols = scale(training_set[, 1:11])
training_set[, 1:11] = training_scaled_cols
test_set[, 1:11] = scale(test_set[, 1:11],
center = attr(training_scaled_cols, 'scaled:center'),
scale = attr(training_scaled_cols, 'scaled:scale'))
# MODELS
### KNN ###
library(kknn)
# Fitting k-NN to the Training set and Predicting the Test set results
classifier = kknn(formula = quality ~ ., train = training_set, test = test_set,
k = 7, distance = 2)
y_pred = classifier$fitted.values
# Showing the Confusion Matrix and Accuracy
library(caret)
cm = confusionMatrix(y_pred, test_set$quality)
print(cm$table)
print(cm$overall['Accuracy'])
### LOGISTIC REGRESSION ###
# Fitting Logistic Regression to the Training set
classifier = glm(formula = quality ~ .,
family = binomial,
data = training_set)
# Predicting the Test set results
prob_pred = predict(classifier, type = 'response', newdata = test_set)
y_pred = as.factor(ifelse(prob_pred > 0.5, 1, 0))
# Showing the Confusion Matrix and Accuracy
library(caret)
cm = confusionMatrix(y_pred, test_set$quality)
print(cm$table)
print(cm$overall['Accuracy'])
### SVM ###
library(e1071)
classifier = svm(formula = quality ~ .,
data = training_set,
type = 'C-classification',
kernel = 'linear')
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set)
# Showing the Confusion Matrix and Accuracy
library(caret)
cm = confusionMatrix(y_pred, test_set$quality)
print(cm$table)
print(cm$overall['Accuracy'])
